{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"WN2Vec","text":"<p>The original word2vec method operates on individual words (tokens). However, many biomedical concepts span multiple tokens. For instance, Myocardial Infarction would be treated by word2vec as two words, but it represents a single medical concept. For this reason, recent approaches collapse multiword concepts into a single token prior to embedding by replacing the multiword concepts with a single concept id (e.g., MeSH:D009203).</p> <p>In this project, we reasoned that replacing synonyms of non-biomedical concepts with the same identifier would additionally improve the performance of word2vec. WordNet is a database of synonyms, hyponyms, and meronyms that groups synonyms from the same lexical category (nouns, verbs, adjectives, and adverbs) into synsets.</p>"},{"location":"#running-the-wn2vec-pipeline","title":"Running the WN2Vec pipeline","text":"<p>To reproduce the results in the manuscript, the following steps should be performed. Additionally, a detailed start to finish tutorial is provided with a relatively small input dataset.</p>"},{"location":"#1-installation-download-data","title":"1. Installation &amp; Download data","text":"<p>See installation for instructions on how to set up the package.</p>"},{"location":"#pubmed-abstracts","title":"PubMed abstracts","text":"<p>To obtain PubMed abstracts, follow the instructions of the NCBI Download PubMed Data website.</p>"},{"location":"#2-replacement-of-biomedical-concepts","title":"2. Replacement of biomedical concepts","text":"<p>We use the marea package to replace single- or multi-word biomedical concepts with concept identifiers.</p> <p>See marea for instructions on how to run marea to perform biomedical concept replacement.</p>"},{"location":"#3-wordnet-based-synonym-replacement","title":"3. WordNet-based synonym Replacement","text":"<p>Next we performed non-biomedical synonyms replacement using WordNet identifiers from the WordNet library.</p> <p>See wordnetreplacement for details and instructions to perform WordNet-based synonym replacement.</p>"},{"location":"#4-word2vec-embedding","title":"4. word2vec embedding","text":"<p>We perform word2vec embedding using the Gensim word2vec model. In order to compare the results of embedding with and without WordNet replacement, embedding is performed on both datasets separately.</p> <p>See word2vec for details and instructions to perform word2vec embedding.</p> <p>This step has to be run twice, first for marea output (pubtator) and second for step 3 output, where concepts were replaced by their synonyms, before going to the following step.</p>"},{"location":"#5-evaluating-concept-sets","title":"5. Evaluating concept sets","text":"<p>Our hypothesis is that non-biomedical concept synonym replacement will improve embeddings as judged by a smaller distance of related concepts to each other.</p> <p>To assess this, we defined 5 different biomedical concept sets representing genetic and genomic functions (gene sets) and biomedical concepts taken from MeSH  (four  sets of gene concept sets and one set of MeSH concept sets):</p> <ul> <li> <p>biocarta canonical gene set</p> </li> <li> <p>kegg canonical gene set</p> </li> <li> <p>(GO) bp gene ontology gene set </p> </li> <li> <p>pid canonical gene set </p> </li> </ul> <p>We used the word2vec embeddings of each concept in the sets to evaluate the impact of WordNet-based synonym replacement using the mean cluster cosine distance of the corresponding concepts.</p> <p>See conceptset_evaluation for details.</p>"},{"location":"#feedback","title":"Feedback","text":"<p>The best place to leave feedback, ask questions, and report bugs is the WN2vec Issue Tracker.</p>"},{"location":"attic/","title":"ATTIC","text":"<p>Move these texts somewhere else</p> <p>Before running the two files in word2vec, ensure that they have the same format. Run the following bash script through the terminal to remove the PubMed identifier and publication year columns, leaving only the abstract from  <code>pubmed_filt.tsv</code>:</p> <p>For Unix-like shell (like Mac) use:     <pre><code>awk -F'\\t' '{print $3}' pubmed_filt.tsv &gt; pubmed_filt_abst.tsv\n</code></pre> For Windows use:     <pre><code>Get-Content pubmed_filt.tsv | ForEach-Object { ($_ -split \"`t\")[2] } | Set-Content pubmed_filt_abst.tsv\n</code></pre></p>"},{"location":"concept_sets/","title":"Concept Sets","text":"<p>New users of this software can create concept sets for testing in any way that is appropriate to their use case. Here, we describe how we generated concepts sets in case it is useful for others. </p>"},{"location":"concept_sets/#medical-subject-headings-mesh","title":"Medical Subject Headings (MeSH)","text":"<p>We manually reviewed MeSH entries using the MeSH Browser and chose identifiers of entries that describe a group of related medical concepts. We selected 105 concepts in this way, and the following table shows the first four of them (the entire list can be found in the file mesh_target_ids.tsv).</p> mesh.id label D001145 Arrhythmias, Cardiac D007674 Kidney Diseases D009202 Cardiomyopathies D001523 Mental Disorders <p>The Python script <code>meshImporter.py</code> was used to retrieve all of the descendant terms of each of these identifiers. For instance, Arrhythmias, Cardiac has 40 descendant terms including Adams-Stokes Syndrome (D000219) and Arrhythmia, Sinus (D001146). The <code>meshImporter.py</code> script retrieves these terms and writes them in a file with the following structure</p> Arrhythmias, Cardiac D001145 meshd016170;meshd000219; (...) Kidney Diseases D007674 meshd016263;meshd000141;meshd058186; (...) Cardiomyopathies D009202 meshd000092183;meshd019571; (...) Mental Disorders D001523 meshd015526;meshd000275; (...) <p>For convenience, the output of this script is stored in the file mesh_sets.tsv and does not need to be recreated to run the other scripts.</p>"},{"location":"conceptset_evaluation/","title":"Concept Set Evaluation","text":"<p>This stage involves running the <code>run_word2vec.py</code> script on two outputs: the filtered marea output (<code>pubmed_filt_abst.tsv</code>) and the WordNet replacement output (<code>pubmed_wn.tsv</code>), resulting in two sets of metadata and vector files.</p> <p>The objective here is to assess whether replacing non-medical concepts with synonyms improves the efficiency of medical term embeddings.</p>"},{"location":"conceptset_evaluation/#overview-of-concept-sets","title":"Overview of Concept Sets","text":"<p>Refer to concept sets for information on how we generated biomedical concept sets for testing. The wn2vec scripts leverage concept sets to evaluate the quality of concept embeddings, drawing gene sets from MSigDB and clinical concept sets from MeSH.</p> <p>Additionally, we used 965 gene sets. The format of the wn2vec conceptset file is     <pre><code>HAY_BONE_MARROW_NEUTROPHIL  M39203  ncbigene55365;ncbigene23129;ncbigene8935;ncbigene3920;ncbigene221; (...)\n</code></pre></p> <p>i.e., name, id, and semicolon-separated list of concept identifiers.  For instance,  <code>ncbigene55365</code> refers to <code>TMEM176A</code> (transmembrane protein 176A; Homo sapiens) which has NCBI Gene ID: 55365.</p>"},{"location":"conceptset_evaluation/#gene-set-transformation-script","title":"Gene Set Transformation Script","text":""},{"location":"conceptset_evaluation/#msigdbgenesettransformerpy","title":"mSigDBgeneSetTransformer.py","text":"<p>Function: Converts gene sets from MSigDb into WN2VEC format.</p> <p>Usage:</p> <ul> <li><code>-i</code> input directory with gene sets (MSigDb) files.</li> <li><code>-o</code>  output file for a .tsv file with the required format for WN2VEC. Default <code>../data/gene_sets.tsv</code> .</li> <li>Example: <code>python mSigDBgeneSetTransformer.py -i ../data/kegg_canonical_gene_set -o data/gene_sets.tsv</code></li> </ul> <p>To test different gene sets, alternate the input directory to a specific gene set directory.</p>"},{"location":"conceptset_evaluation/#mesh-set-importer-script","title":"Mesh Set Importer Script","text":""},{"location":"conceptset_evaluation/#meshimporterpy","title":"meshImporter.py","text":"<p>Function: Downloads and formats mesh sets from Mesh Database.</p> <p>Usage:</p> <ul> <li>Reads <code>data/mesh_target_ids.tsv</code> for target mesh IDs.</li> <li>Saves formatted data in <code>../data/mesh_sets.tsv</code>.</li> <li>Example: <code>python meshImporter.py</code></li> </ul>"},{"location":"conceptset_evaluation/#embedding-comparison-script","title":"Embedding Comparison Script","text":""},{"location":"conceptset_evaluation/#compare_embeddingspy","title":"compare_embeddings.py","text":"<p>Function: Compares embeddings from <code>pubmed_filt_abst.tsv</code> and <code>pubmed_wn.tsv</code> using selected MeSH and gene sets.</p> <p>Parameters:</p> <ul> <li><code>-i</code>: TensorFlow file directory.</li> <li><code>-c</code>: Concept set directory.</li> <li><code>-p</code>: Prefix for PubTator TensorFlow files.</li> <li><code>-w</code>: Prefix for WordNet TensorFlow files.</li> <li><code>-o</code>: Output file name.</li> <li>Example: <code>python compare_embeddings.py -i ../data/metadata_threshold -c ../data/bio_geneset.tsv -p pubt -w wn -o comn_concepts.tsv</code></li> </ul>"},{"location":"conceptset_evaluation/#concise-results-interpretation","title":"Concise Results Interpretation","text":"<ul> <li>Objective: Evaluate the impact of synonym replacement on embedding efficiency.</li> <li>Method: Compare mean distances in concept clusters between <code>pubmed_filt_abst.tsv</code> and <code>pubmed_wn.tsv</code>.</li> <li>Criteria: A true count is recorded if a gene set/mesh set\u2019s mean in <code>pubmed_wn.tsv</code> is lower than in <code>pubmed_filt_abst.tsv</code>.</li> <li>Threshold: Consider sets with at least 3 common vocabularies in the metadata files.</li> </ul> <p>The results highlight the effectiveness of synonym replacement in improving the clustering of biomedical concepts.</p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#installation-of-wn2vec-environment","title":"Installation of wn2vec environment","text":"<p>To install package from PyPI locally:</p> <ul> <li>create a virtual environment</li> <li>pip-install the build package</li> <li>do a local build</li> </ul> <p>Then we can use the scripts in the 'scripts' subdirectory with the wn2vec package to run the rest of the files</p> <p>This is how to build install wn2vec locally <pre><code>python3 -m venv venv\nsource venv/bin/activate\npip install .\n</code></pre></p>"},{"location":"marea/","title":"Running marea","text":"<p>MAREA (marea adamantly resists egregious acronyms) is a tool for processing PubMed abstracts. Ravanmehr et al for additional information.</p> <p>The README of marea presents details on how to run the scripts. For the current project, we downloaded abstracts from NCBI's FTP site, which makes available gzipped .xml files containing titles, abstracts, and metadata for all PubMed articles. We used the <code>xml2txt.py</code> script to extract the required fields from the abstracts. We then chose abstracts published between 2010 and 2020.</p>"},{"location":"marea/#using-your-own-data-and-concept-replacement-tool","title":"Using Your Own Data and Concept Replacement Tool.","text":"<p>For our experiments, we used PubTator to perform concept replacement, and the above file has already been processed with PubTator. You can use any analogous file and perform concept replacement by any method. Ensure the output is formatted in three tab-separated columns with column 1 being the PubMed identifier, column 2 being the year of publication, and column 3 being the abstract text with concept replacements. The following table shows an example.</p> Column 1 Column 2 Column 3 35509584 \u00a02022 \u00a0endoscope control extend ... meshd009369 frontal convexity technical note .... \u00a035444774 \u00a02022 \u00a0meshd008223 ncbigene4609 ncbigene4609 ncbigene596 ncbigene596 ncbigene604 ncbigene604 rearrangement review diagnosis treatment modern era classification meshd009369 depends immunomorphological 34433723 2021 \u00a0 unusual meshd006471 mimic rupture solitary gastric varix due meshd046152 exogenous growth meshd046152 lead meshd006471 usual"},{"location":"marea/#pubtator","title":"PubTator","text":"<p>Biomedical concept replacement was performed using resources from the PubTator Central project. The <code>pubtate.py</code> script from the marea project was used to process the above files.</p>"},{"location":"stop_words/","title":"Stop words","text":""},{"location":"stop_words/#how-marea-handles-stop-words","title":"How Marea Handles Stop Words","text":"<p>Marea's approach to handling stop words includes several criteria:</p> <ul> <li>Whether lowercase or Capitalized.</li> <li>Marea starts with the NLTK stop word list for English and adds some new stop words.</li> <li>Any token that starts with a digit (even if the rest of the string includes some letters) is treated as numerical and discarded if it is not one of the interesting numbers.</li> <li>Any letter of the alphabet that occurs as a single-character token is a stop word.</li> </ul>"},{"location":"stop_words/#nltk-stop-words","title":"NLTK Stop Words","text":"<p>The NLTK Stop Words can be found at NLTK Stop Words.</p> <p>Currently, there are 179 English stop words:</p> <p>{\"doesn't\", 'she', \"hasn't\", 'the', 'yourself', 'ma', 'what', 'aren', 'from', 'me', 'haven', 'which', 'on', 'no', 'your', 'him', 'being', 'they', 'whom', 'weren', 'off', 'herself', 'couldn', 'so', 'should', 'them', 'all', 'any', 'd', 'more', 'we', 'as', 'each', 'hadn', 'theirs', 'needn', 'few', \"you've\", 'or', 'it', 'our', 'in', 'does', 'very', 'isn', 'mightn', 'was', 'then', 'under', 'before', 'but', 'below', 'further', 'himself', 've', \"wasn't\", 'only', 'ain', \"you'll\", 'mustn', 'hers', 'for', 'where', \"hadn't\", 'his', 'yourselves', \"it's\", \"won't\", \"you'd\", 'are', 'some', 't', 'been', 'such', 'when', 'shan', 'during', \"didn't\", 'i', 'is', 'were', \"mightn't\", 'own', \"shan't\", 'had', 'by', \"shouldn't\", 'up', 'out', 'ourselves', 'because', 'at', 'who', 'how', 'with', 'to', 'doing', \"don't\", 'of', 'wouldn', 'too', 'do', 'a', 'once', 'down', 'don', \"isn't\", 'than', 'this', 'm', 'these', 'through', 're', 'my', 'doesn', \"weren't\", 'll', 'you', 'if', \"you're\", 'here', 'her', \"mustn't\", 'wasn', 'just', \"she's\", 'have', 'an', 'he', 'myself', 'and', 'didn', 'y', 'themselves', \"couldn't\", 'o', 'did', 'against', 'can', \"aren't\", \"should've\", 'into', 'while', 'its', 'both', 'ours', 'again', 'won', 'after', 'has', 'most', 'until', 's', 'hasn', \"that'll\", 'those', 'am', 'yours', 'there', 'now', 'over', 'itself', 'nor', 'above', \"haven't\", 'between', 'other', 'having', 'why', 'their', 'will', \"wouldn't\", 'about', 'not', \"needn't\", 'that', 'be', 'shouldn', 'same'}</p>"},{"location":"stop_words/#additional-stop-words","title":"Additional Stop Words","text":"<p>Marea includes additional stop words:</p> <p>'also', 'cannot', 'could', 'furthermore', 'however','may', 'might', 'non', 'thus', 'whose', 'within','without', 'would'</p>"},{"location":"stop_words/#interesting-numbers","title":"Interesting Numbers","text":"<p>Marea treats the following numbers as interesting and does not discard them:</p> <p>interesting_numbers = {'001', '01', '05', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '95', '99', '100'}</p>"},{"location":"tutorial/","title":"Tutorial","text":"<p>Here, we demonstrate all the steps required to run the wn2vec pipeline on a small input dataset consisting of 100,000 abstracts from PubMed. The pipeline can be run similarly with all PubMed abstracts or any other input source.</p>"},{"location":"tutorial/#1-setting-up-the-environment","title":"1. Setting Up the Environment","text":"<p>There are several ways to run the code, but the simplest is to set up a virtual environment. We call the environment <code>wn2v_env</code> in this example, but you can use any name you like.</p> <p><pre><code>python3 -m venv wn2v_env\nsource wn2v_env/bin/activate\npip install .\n</code></pre> Note that wn2vec requires Python 3.</p>"},{"location":"tutorial/#2-downloading-the-data","title":"2. Downloading the Data","text":"<p>The input data for this tutorial consists of a file with 100,000 abstracts from PubMed that have been processed using the marea pipeline for medical concept replacement.</p> <p>The file can be downloaded from Zenodo: pubmed_cr.tsv.</p>"},{"location":"tutorial/#3-optional-preparing-the-input-file-with-marea","title":"3 (Optional) Preparing the input file with marea","text":"<p>The file we downloaded above has been pre-processed using MAREA. For new data, you will need to use marea or an analogous tool. See Running marea for details.</p>"},{"location":"tutorial/#4-filter-by-year","title":"4. Filter By Year","text":"<p>After you have downloaded the <code>pubmed_cr.tsv</code> file (or prepared your own input file to have the same format), the next step is to filter by certain year if you want.</p> <p>For example if you would like publication above the year of 2010, if you would like to proceed with all the text, please skip this step:</p> <pre><code>cd scripts\npython filter_by_year.py -i ../pubmed_cr.tsv -o ../pubmed_filt.tsv -y 2010\n</code></pre>"},{"location":"tutorial/#5-wordnet-replacement","title":"5. WordNet Replacement","text":"<p>We proceed with the <code>pubmed_filt.tsv</code> file (or prepared your own input file to have the same format), the next step is to perform the WordNet non-biomedical concept replacement. Run the following script (which is in the <code>scripts</code> directory -- note that the example does not show full paths).</p> <pre><code># Note: still in scripts folder\npython run_wn_replacement.py -i ../pubmed_filt.tsv -p PREFIX [--threshold &lt;float&gt;]\n</code></pre> <p>The <code>-i</code> argument points to the input file. The <code>-p</code> argument is a prefix that will be used to create two files:</p> <ul> <li>PREFIX-WN.txt: Text of the abstracts with WordNet replacements, one abstract per line</li> <li>PREFIX-abstracts.txt: Text of the abstracts without WordNet replacements, one abstract per line</li> </ul> <p>The <code>--threshold</code> is a floating number that controls the minimum (threshold) count of a synonym to be replaced. First, the mean word count of all words (tokens) in the entire corpus is determined. For example, the mean could be \u03bc = 400, meaning that the average word occurs 400 times in the entire corpus of texts. If the threshold is set to \u03c4 = 2.0, then, the minimum count for being replaced would be \u03c4\u03bc = 800.</p> <p>The output file has the same number of abstracts as the input file, except that some words are replaced by more common synonyms, and the format changed to be just one column which is the abstracts only.</p> <p>When the script is run, it will either download or preload the WordNet vocabulary (which may take a minute or so). Once it starts to perform sysnonym replacement, you will see a progress bar similar to the following.</p> <p></p>"},{"location":"tutorial/#input-text-excerpt","title":"Input Text (Excerpt)","text":"<p>The text is formatted in three tab-separated columns with column 1 being the PubMed identifier, column 2 being the year of publication, and column 3 being the abstract text with concept replacements. The following table shows an example.</p> <p>33500803  2020    colloid cyst curtail case report spontaneous colloid cyst regression (...) discover colloid cyst image perform transient meshd009461 ct mri brain reveal 5mm lesion</p>"},{"location":"tutorial/#wordnet-replaced-text-excerpt","title":"WordNet-Replaced Text (Excerpt)","text":"<p>colloid cyst restrict case report spontaneous colloid cyst regression (...) discover colloid cyst image perform transient meshd009461 ct mri brain reveal 5mm lesion</p> <p>Thus, the relatively rare word <code>curtail</code> was replaced by the more common synonym <code>restrict</code>.</p>"},{"location":"tutorial/#6-word2vec","title":"6. Word2Vec","text":"<p>The next step is to run word2vec on the replaced input file. If desired, word2vec can be run on both files for comparison purposes; the steps are analogous.</p> <p>Now, run each file with abstracts through word2vec. If you want to compare both files to test the impact of WordNet-based synonym replacement, run the following code twice:</p> <pre><code>python run_word2vec.py -i pubmed_filt_abst.tsv -p pm\npython run_word2vec.py -i pubmed_wn.tsv -p wn\n</code></pre> <p>Running the script with the argument <code>-p</code> (long form <code>--prefix</code>) to \"pm\" will create output files pm_vector.tsv and pm_metadata.tsv.</p> <p>Remember to run this code twice with separate paths for the input and different names for vectors and metadata if you want to compare two separate files. Note: all custom vector names should end with '_vector' and metadata should end '_metadata'.</p>"},{"location":"tutorial/#7-compare-embeddings","title":"7. Compare Embeddings","text":"<p>This step comes after you have 2 vector files and 2 metadata files for two separate corpora generated from the step above. This step evaluates the impact of WordNet-based synonym replacement on the corpus. The test will be done on different biomedical sets as detailed in Concept Set Evaluation:</p> <pre><code>python compare_embeddings.py -i metadata_vectors/ -c data/bio_geneset.tsv -p filt -w wn -o /comn_concepts.tsv\n</code></pre> <p>Repeat this step for multiple concept sets to check how different concepts' embeddings behave.</p>"},{"location":"tutorial/#8-result-interpretation","title":"8. Result Interpretation","text":"<p>We performed two tests, one is the cluster mean distance between genes of the same set, and the second is PairTest.</p> <ul> <li>WN: refers to the WordNet replaced corpus.</li> <li>PM: refers to the marea output (none of the concepts were replaced using WordNet).</li> </ul> <p>For example:</p> <ul> <li>WN relevant concepts 1302 and PM relevant concepts 1302: This means there were 1302 genes both in the WN and PM corpus, and in the biocarta_canonical_gene_set (concept set).</li> <li>WN sig 22 and PM sig 3: This indicates that 22 concept sets in the WN corpus had a significantly lower cluster mean distance compared to only 3 in the PM corpus.</li> <li>WN LESS 165 and PM LESS 117 (irrespective of p-value): There were 165 concept sets in WN with a lower cluster mean distance compared to 117 in PM.</li> <li>WN sig PairTest 106249 and PM sig PairTest 90127</li> <li>WN LESS PairTest 130706 and PM LESS PairTest 113559 (irrespective of p-value)</li> </ul>"},{"location":"tutorial/#explanation","title":"Explanation:","text":"<ul> <li>WN vs. PM: The comparison is between two different corpora - one processed with WordNet (WN) and the other with marea (PM).</li> <li>Relevant Concepts: The number (1302) signifies the count of genes common between the analyzed corpus and a specific gene set.</li> <li>Significance (sig): The number of concept sets where the WordNet approach showed a statistically significant improvement in clustering compared to marea.</li> <li>LESS: Indicates the number of concept sets where the mean distance between concepts is less (closer), suggesting better clustering or relatedness in the corpus.</li> <li>PairTest: Represents a detailed comparison test between the two corpora, indicating how many times one performed better than the other in terms of clustering concepts.</li> </ul>"},{"location":"word2vec/","title":"Word2Vec","text":"<p>Now we have two files to compare. We have the marea output which was filtered by year (<code>pubmed_filt.tsv</code>) and WordNet-transformed text (<code>pubmed_wn.tsv</code>).</p>"},{"location":"word2vec/#transforming-input-text","title":"Transforming input text","text":"<p>To ensure that we have fair results after embedding, the input text should be in the same formart. Currently <code>pubmed_wn.tsv</code> have only one column which is abstracts, we are going to remove extra columns from  <code>pubmed_filt.tsv</code> to have same formart. </p> <p>Run the following comand in your terminal</p> <p>For Unix-like shell (like Mac) use:      <pre><code>awk -F'\\t' '{print $3}' pubmed_filt.tsv &gt; pubmed_filt_abst.tsv\n</code></pre> For Windows use:     <pre><code>Get-Content pubmed_filt.tsv | ForEach-Object { ($_ -split \"`t\")[2] } | Set-Content pubmed_filt_abst.tsv\n</code></pre></p>"},{"location":"word2vec/#word2vec-embedding","title":"Word2Vec Embedding","text":"<ul> <li> <p>This step has to be run twice, first for <code>pubmed_filt_abst.tsv</code> and second for <code>pubmed_wn.tsv</code> before going to the following step.</p> </li> <li> <p>Word2vec converts the texts from abstracts to build word embedding using Skip-gram and negative sampling using Gensim Word2vec model.</p> </li> <li> <p>We used a continuous skip-gram model, where we were predicting words within a certain range before and after the current word in the same sentence.</p> </li> <li> <p>The model is trained on skip-grams, which are n-grams that allow tokens to be skipped.</p> </li> <li> <p>The context of a word can be represented through a set of skip-gram pairs of (target_word, context_word) where context_word appears in the neighboring context of target_word.</p> </li> <li> <p>The training objective of the skip-gram model is to maximize the probability of predicting context words given the target word.</p> </li> </ul>"},{"location":"word2vec/#running-the-word2vec-script","title":"Running the Word2Vec Script","text":"<p><code>run_word2vec.py</code> takes three command-line options:</p> <ul> <li> <p><code>-i</code>: Path to a .tsv file with abstracts (either <code>pubmed_filt_abst.tsv</code> or <code>pubmed_cr.tsv</code>).</p> </li> <li> <p><code>-v</code>: Name of output vector file (ex. <code>wn_vector</code>).</p> </li> <li> <p><code>-m</code>: Name of output metadata file (ex. <code>wn_metadata</code>).</p> </li> </ul> <p>Remember to run this code twice with separate paths for the input and different names for vectors and metadata if you want to compare two separate files. </p> <p>Note: all custom vector names should end with <code>_vector</code> and metadata should end <code>_metadata</code>.</p> <p>To run the code:</p> <ol> <li> <p>On local laptop:</p> <ul> <li>Locate the file you are running, then use Python to execute <code>run_word2vec.py</code> with the appropriate arguments.</li> <li>Example: <code>python run_word2vec.py -i pubmed_wn.tsv -v wn_vector -m wn_metadata</code></li> </ul> </li> <li> <p>On High Performance Computing (HPC):</p> <ul> <li>Run the  singularity file <code>singularity/word2vector.sh</code> as <code>sbatch -q batch word2vector.sh</code>.</li> </ul> </li> </ol> <p>The output files consist of:</p> <ul> <li>A vector file: contains a list of vectors equal to the number of vocab size and the metadata. The vector file has 128 dimensions for each vocabulary.</li> <li>A metadata file: contains a list of vocabularies.</li> </ul> <p>Once this step is repeated twice for both the filtered abstracts and the corresponding WordNet transformed file, we have 2 metadata files and 2 vector files which will be used in the evaluation.</p>"},{"location":"wordnetreplacement/","title":"WordNet replacement","text":""},{"location":"wordnetreplacement/#wordnet-based-synonym-replacement","title":"WordNet-based synonym Replacement","text":"<p>After getting the pre-processed data where biomedical concepts have been replaced as the results of Marea (pubmed_cr), the following steps are taken:</p>"},{"location":"wordnetreplacement/#input-data","title":"Input Data","text":"<p>The <code>pubmed_cr.tsv</code> file will have 3 columns: PubMed ID, Publication Year, and abstract.</p>"},{"location":"wordnetreplacement/#first-step-filtering-by-year","title":"First Step: Filtering by Year","text":"<p>Use the script <code>scripts/filter_by_year.py</code> to filter the whole dataset with a certain year you want to use. For example, if you want all published PubMed article\u2019s abstracts from 2010 up to the latest, you will use 2010 as a threshold year.</p> <p><code>filter_by_year.py</code> takes three command-line options:</p> <ul> <li> <p><code>-i</code>: Path of a .tsv Marea file output (<code>pubmed_cr.tsv</code>)</p> </li> <li> <p><code>-o</code>: Path to .tsv output file where the output will go (<code>pubmed_filt</code>)</p> </li> <li> <p><code>-y</code>: Threshold year, all PubMed published above the year will be saved in the output file</p> </li> </ul> <p>To run the code:</p> <ol> <li> <p>On local laptop:</p> <ul> <li>Locate the file you are running, then use Python to execute <code>filter_by_year.py</code> with the appropriate arguments.</li> <li>Example: <code>python /filter_by_year.py -i ../pubmed_cr.tsv -o ../pubmed_filt.tsv -y 2010</code></li> </ul> </li> <li> <p>On High Performance Computing (HPC):</p> <ul> <li>Run the singularity file <code>singularity/filter_by_year.sh</code> as <code>sbatch -q batch filter_by_year.sh</code>.</li> </ul> </li> </ol>"},{"location":"wordnetreplacement/#second-step-wn-replacement","title":"Second Step: WN Replacement","text":"<p>In this step, we replace non-medical concepts with their synonyms using the WordNet library from NLTK. This means that words with the same synonyms are replaced by one synonym ID.  For example, good, well, better, best, effective can be replaced with a single word like good.</p> <p>The words are sorted by their frequency of occurrence in the whole file, and all the words whose frequency is less than the threshold, are subjected to be replaced with their synonym word. The threshold is the mean of the frequency of occurrence of all vocabularies in the text.</p> <p><code>run_wn_replacement.py</code> takes two command-line options:</p> <ul> <li> <p><code>-i</code>: Path of a .tsv filtered Marea file output (<code>pubmed_filt.tsv</code>)</p> </li> <li> <p><code>-o</code>: Path to .tsv output file where the output will go (<code>pubmed_wn.tsv</code>)</p> </li> <li> <p><code>--threshold</code>: This is a floating number that controls the minimum (threshold) count of a synonym to be replaced (default <code>--threshold 1</code>).  </p> </li> </ul> <p>To run the code:</p> <ol> <li>On local laptop:<ul> <li>Locate the file you are running, then use Python to execute <code>run_wn_replacement.py</code> with the appropriate arguments.</li> <li>Example: <code>python3 run_wn_replacement.py -i pubmed_filt.tsv -o pubmed_cr.tsv [--threshold &lt;float&gt;]</code></li> </ul> </li> <li>On High Performance Computing (HPC):<ul> <li>Run the  singularity file <code>singularity/wntransformer.sh</code> as <code>sbatch -q batch wntransformer.sh</code>.</li> </ul> </li> </ol> <p>The output of this step is a .tsv file with 1 column which is the abstract of each article. The WN transformed file has the same number of abstracts as the filtered Marea output.</p>"}]}