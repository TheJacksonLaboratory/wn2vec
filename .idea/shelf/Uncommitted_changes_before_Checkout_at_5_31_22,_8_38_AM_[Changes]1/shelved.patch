Index: wn2vec/wntransformer.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import nltk\nfrom nltk.corpus import wordnet as wn\nfrom typing import List, Dict\n\nimport os\nfrom collections import defaultdict\n\n\nclass WordNetTransformer:\n\n    def __init__(self, marea_file, do_not_replace_threshold: int = 20) -> None:\n        \"\"\"\n        Path to the file produced by marea\n        \"\"\"\n        if not os.path.exists(marea_file):\n            raise FileNotFoundError(\"Could not find marea file\")\n\n        self._marea_file = marea_file\n        self._counter = defaultdict(int)\n        # Get count of words in corpus\n        with open(marea_file) as f:\n            for line in f:\n                words = line.split()\n                for w in words:\n                    # TODO skip stop words\n                    self._counter[w] += 1\n        # Create synonym dictionary with NLTK\n        # if needed, install wordnet\n        nltk.download(\"wordnet\")\n        # sorted(d.items(), key=lambda item: item[1])\n        # words_sorted_by_frequency = sorted(self._counter, key=lambda item: item[1], reverse=True)\n        # {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}\n        words_sorted_by_frequency = [k for k, v in\n                                     sorted(self._counter.items(), key=lambda item: item[1], reverse=True)]\n        self._do_not_replace_threshold = do_not_replace_threshold\n        self._dict = self.dictCreate(words_sorted_by_frequency)\n\n    def dictCreate(self, word_list) -> Dict:\n        \"\"\"\n        Creates a dictionary from the whole data set, they keys are in order of their frequency words\n        and the values are synonyms of keys from synset\n        @argument: 'word_list' a list of unique words from the whole dataset in order of frequency\n        @return: a dictionary of all the variables in the dataset, the keys are the unique variables\n                   with high frequency, and values are key's synonym\n        \"\"\"\n        dictionary = {}\n        for i in range(len(word_list)):\n            this_word = word_list[i]\n            # skip common words\n            this_word_count = self._counter.get(this_word, 0)\n            if this_word_count > self._do_not_replace_threshold:\n                continue\n            synonym_list = self.synonym(this_word)\n            dictionary[this_word] = self._highest_count_synonym(synonym_list)\n        return dictionary\n\n    def _highest_count_synonym(self, synonym_list):\n        \"\"\"\n        :param synonym_list: a list of a word and its synonyms in Wordnet\n        :return: The word (synonym) with the highest count in our dataset\n        \"\"\"\n        if len(synonym_list) == 0:\n            raise ValueError(\"synonym_list was length zero, should never happen\")\n        max_count = 0\n        max_word = synonym_list[0]\n        for s in synonym_list:\n            c = self._counter.get(s, 0)\n            if c > max_count:\n                max_word = s\n                max_count = c\n        return max_word\n\n    def synonym(self, word: str) -> List:\n        \"\"\"\n        @argument: 'word' A word from the input dataset\n        @return: a list of synonyms of the words\n        \"\"\"\n        synonyms = [word]\n        for syn in wn.synsets(word):\n            for l in syn.lemmas():\n                synonyms.append(l.name())\n        return synonyms\n\n    def transform(self, sentence: str) -> str:\n        pass
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/wn2vec/wntransformer.py b/wn2vec/wntransformer.py
--- a/wn2vec/wntransformer.py	
+++ b/wn2vec/wntransformer.py	
@@ -81,5 +81,22 @@
                 synonyms.append(l.name())
         return synonyms
 
+    def replace_data_set(self, data_list, dictionary) ->List:
+
+        """
+        Replaces the variable in dataset with their synonyms from the dictionary
+        @argument: 'data_list' a list of all the data_set in form of a list
+                          "dictionary" a dictionary created with the whole dataset
+        @return: 'data_list' a new list with the whole list where the words were replaced by their synonyms
+
+        """
+
+        for i in range(len(data_list)):
+            if data_list[i] in dictionary:
+                data_list[i] = dictionary.get(data_list[i])
+            else:
+                raise ValueError("the word is not in the dictionary")
+        return (data_list)
+
     def transform(self, sentence: str) -> str:
         pass
\ No newline at end of file
Index: tests/test_replace.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/tests/test_replace.py b/tests/test_replace.py
deleted file mode 100644
--- a/tests/test_replace.py	
+++ /dev/null	
@@ -1,41 +0,0 @@
-import unittest
-from script.replace import*
-
-import nltk
-
-#nltk.download("wordnet")
-from nltk.corpus import wordnet as wn # Import Wordnet
-from collections import Counter  # Import Counter
-import numpy as np
-import csv
-
-class ReplaceTestCase(unittest.TestCase):
-    def test_sort_words_by_count(self):
-        test1 = ['cancer', 'disease', 'caused', 'cell', 'crab', 'simple', 'cadre', 'cell', 'cancer', 'disease', 'cell', 'cancer', 'cell']
-        result = Replace.sort_words_by_count(test1)
-        expected = ['cell', 'cancer', 'disease', 'caused', 'crab', 'simple', 'cadre']
-        self.assertEqual(expected, result, 'Arrangement do not match expected.')
-        # 'cancer', 'disease', 'caused', 'cell', 'crab', 'simple', 'cadre']
-
-    def test_synonym(self):
-        expected = ['tissue', 'tissue', 'tissue_paper', 'weave', 'tissue']
-        result = Replace.synonym('tissue')
-        self.assertEqual(expected, result, 'Synonym do not match expected.')
-    
-    def test_dictCreate(self):
-        test_list = ['cadre', 'tissue', 'cell', 'weave', 'cider']
-        expected_dictionary = {'cell': 'cadre', 'cadre': 'cadre', 'tissue': 'tissue', 'tissue_paper': 'tissue', 'weave': 'tissue', 'cider': 'cider', 'cyder': 'cider'}
-        rep = Replace(test_list)
-        d = rep.get_word_dictionary()
-        self.assertEqual(expected_dictionary, d, 'Dictionary created do not match expected.')
-      
-    
-    def test_replace_data_set(self):
-        test_set = ['cell', 'cadre', 'cell', 'dyestuff', 'dye', 'dye']
-        replace = Replace(list=test_set)
-        result = replace.get_replaced_data()
-        expected_set =['cell', 'cell', 'cell', 'dye', 'dye', 'dye']
-        self.assertEqual(expected_set, result, 'Key do not match expected.')
-
-if __name__ == '__main__':
-    unittest.main()
\ No newline at end of file
